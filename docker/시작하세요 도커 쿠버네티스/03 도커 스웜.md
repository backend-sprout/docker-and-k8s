# 도커 스웜 
# 도커 스웜을 사용하는 이유 

하나의 호스트 머신에서 도커 엔진을 구동하다가 CPU 메모리, 디스크 용량과 같은 자원이 부족하면 

* 스케일 업 
* 스케일 아웃(클러스터로 구성)
 
서버를 병렬로 확장해나가면     
적당한 성능의 서버 여러대를 하나의 자원 풀을 만들어 사용할 수 있고 성능이 좋은 값 비싼 서버를 사지 않아도 된다.         

**그러나, 여러대의 서버를 하나의 자원 풀로 만드는 것은 쉬운 작업이 아니다.**       
새로운 서버나 컨테이너가 추가됐을 때 이를 발견(Service Discovery)하는 작업부터   
어떤 서버에 컨테이너를 할당할 것인가에 대한 스케줄러와 로드밸런서 문제,      
클러스터 내의 서버가 다운 됐을 때 **고가용성**을 어떻게 보장할지 등이 문제로 남아있다.      

다행히도 이러한 문제를 해결하는 여러 솔루션을 오픈소스로 활용할 수 있는데   
도커에서 공식적으로 제공하는 도커스웜과 스웜모드가 대표적이다.   

# 스웜 클래식과 도커 스웜 모드 

스웜 클래식/스웜 모드는 여러 대의 도커 서버를 하나의 클러스터로 만들어 컨테이너를 생성하는 여러 기능을 제공한다.       
컨테이너를 특정 도커 서버에 할당할 수 있고 유동적으로 서버를 확장시킬 수도 있다.    
그뿐만 아니라 스웜 클러스터에 등록된 서버의 컨테이너를 쉽게 관리할 수 있다.   
(서버 클러스터에서 컨테이너를 어떻게 다룰 수 있는지 기초적인 지식 쌓기에 적합하다.)   

도커 스웜에는 2가지 종류가 있다.   

1. 스웜 클래식 : 도커 버전 1.6 이후부터 사용할 수 있는 컨테이너로서의 스웜
2. 스웜 모드 : 도커 버전 1.12 이후부터 사용할 수 있는 도커 스웜 모드(Swarm)

## 스웜 클래식과 도커 스웜 모드의 목적

두 종류의 가장 큰 차이점은 **목적**이다.  
  
* 스웜 클래식 : 
    * 여러 도커 서버를 하나의 지점에서 사용하도록 단일 접근점을 제공    
    * docker run, docker ps 등 일반적인 도커 명령어와 도커 API로 클러스터의 서버를 제어하고 관리할 수 있음  
* 스웜 모드 : 
    * 마이크로 서비스 아키텍처의 컨테이너를 다루기 위한 클러스터링 기능에 초점  
    * 같은 컨테이너를 동시에 여러 개 생성해 필요에 따라 유동적으로 컨테이너의 수를 조절 

상황에 맞추어 사용하면 되지만, 스웤 모드가 확장성 안정성 등 여러 측면에서 비교적 뛰어나기에 스웜 모드 사용  

## 분산 코디네이터
> 에이전트와 같은 클러스터 툴이 별도로 구동 되느냐   

여러개의 도커 서버를 하나의 클러스터로 구성하려면 각종 정보를 저장하고 동기화하는 분산 코디네이터,   
클러스터 내의 서버를 관리하고 제어하는 매니저, 각 서버를 제어하는 에이전트가 반드시 있어야 한다.  

* 스웜 클래식 : 분산 코디네이터, 에에전트등이 별도로 실행되어야함  
* 스웜 모드 : 클러스터링을 위한 모든 도구가 도커 엔진 자체에 내장돼있어 쉽게 서버 클러스터 구축이 가능하다.  

```
분산 코디네이터는 클러스터에 영입할 새로운 서버의 발견, 클러스터의 각종 설정 저장, 데이터 동기화 등에 주로 이용된다.   
etcd, zookeeper, consul등이 대표적인 예이며, 스웜 클래식은 대부분 분산 코디네이터를 사용할 수 있다.    
스웜 모드는 분산 코디네이터를 별도로 구축하지 않아도 된다.
```

대규모 클러스터에서 서비스를 운영하는 것을 계획하고 있다면 스웜 클래식보다는 스웜 모드를 사용하는 것이 좋다.  
스웜 모드는 MSA 애플리케이션을 컨테이너로 구축할 수 있도록 도와줄 뿐만 아니라,       
**서비스 장애에 대비한 고가용성과 부하 분산을 위한 로드 밸런싱 기능 또한 제공하고 있기 때문이다.**   
(스웜 클래식도 가능하지만 스웜 모드를 추천)  

# 스웜 모드 
  
스웜 모드는 별도의 설치 고자ㅓㅇ이 필요하지 않으며, 도커 엔진 자체에 내장돼어 있다.(기본은 비활성화)   

```shell
docker info | grep Swarm
Swarm: inactive // 비활성화 
```

## 도커 스웜 모드 구조 

스웜 모드는 매니저 노드와 워커 노드로 구성되어 있다.  

* 매니저 노드 : 워커 노드를 관리하는 도커 서버(워커로도 사용 가능)     
* 워커 노드 : 실제로 컨테이너가 생성되고 관리되는 도커 서버  

![swarm-diagram](https://user-images.githubusercontent.com/50267433/175771693-7899443f-21b0-402f-9bae-82b6e48d600a.png)

기본적으로 매니저 노드는 한 개 이상 있어야 한다.    
노드가 2개이상이 될 경우, 매니저 노드와 워커 노드를 분리해서 사용하는 것이 좋다.(매니저1, 워커2)    
운영에서 사용하려면 매니저 노드를 이중화하는 것을 추천한다.(고가용성)  

스웜 모드는 매니저 노드의 절반 이상에 장애가 생겨 정상적으로 작동하지 못할 경우    
장애가 생긴 매니저 노드가 복구될 때까지 클러스터의 운영을 중단한다.    
 
만약, 매니저 노드 사이에 네트워크 파티셔닝과 같은 현상이 발생했을 경우,      
짝수 개의 매니저로 구성한 클러스터는 운영이 중단될 수 도 있지만,     
홀수 개로 구성햇을 경우에는 과반수 이상이 유지되는 쿼럼 매니저에 운영을 계속할 수 있다.   


## 도커 스웜 모드 클러스터 구축 

```
swarm-manager 192.168.0.100
swarm-worker1 192.168.0.101
swarm-worker2 192.168.0.102
```
```
docker swarm init --advertise-addr 192.168.0.100

Swarminitialized : ~~
To add a worker ~~~
    docker swarm join \
    --token ~~~ \
    IP
    
To add a manager to ~~    
```
* `docker swarm init --advertise-addr {IP}` 를 통해 매니저 노드를 실행시킨다.
* 만약 매니저 노드가 2개 이상의 네트워크 인터페이스르 가지고 있다면,      
  어느 IP 주소로 매니저에 접근해야할지 다른 노드에 알려줄 필요가 있다.   
* 출력 결과중 `docker swarm join` 이라는 명령어는 새로운 워커 노드를 스웜 클러스터에 추가할 때 사용한다.       
  `--token` 옵션에 사용된 토큰 값은 새로운 노드를 해당 스웜 클러스터에 추가하기 위한 비밀키다.    

```
스웜 매니저는 기본적으로 2377번 포트를 사용하며,    
노드 사이의 통신에 7956/tcp, 7946/udp 포트를 스웜이 사용하는 네트워크인 ingress 오버레이 네트워크에   
4789/tcp, 4789/udp 포트를 사용한다.   
스웜 클러스터를 구성하기 전에 이러한 포트를 각 호스트 머신에서 열어두는 것을 잊지말자  
```

위 출력 결과에서의 토큰을 이용해 워커 노드를 등록하고자 한다면 아래와 같다.  

```
워커 노드 서버>> 

docker swarm join \
--token {{토큰}}
{{매니저 노드 IP}}
```
* 각 워커노드마다 실행해야 한다.  

```
> 매니저 노드 

docker node ls
ID      HOSTNAME      STATUS      AVAILABILITY      MANAGER      STATUS
~
```
* 스웜 클러스터에 어떤 워커 노드가 추가되었는지 확인하기 위해서,   
  매니저 노드에 `docker node ls`를 입력하면 알 수 있다.     
   
매니저 노드는 일반적으로 매니저 역할을 하는 노드와 리더 역할을 하는 노드로 나뉜다.      
리더 매니저는 모든 매니저 노드에 대한 데이터 도익화와 관리를 담당하므로 항상 작동할 수 있는 상태여야한다.      
리더 매니저의 서버가 다운되는 등의 장애가 생기면 매니저는 새로운 리더를 선출하는데, 이 때 Raft Consensus 알고리즘을 사용한다.     
Raft Consensus 알고리즘은 리더 선출 및 고가용성 보장을 위한 알고리즘이다.     
한개의 매니저만 존재할 경우, 해당 노드가 리더가 된다.    
  
```
docker swarm join-token manager  

    docker swrm join \
    --token {{토큰}}
    {{리더매니저IP:2377}}
```

새로운 매니저 추가는 기존 매니저 노드에서 위 명령어를 통해 확인이 가능하다.  

```
docker swarm join join-token --rotate {{manager/~~}} 
```

토큰은 가급적 공개되지 않아야하고 주기적으로 변경을 해주는 것이 좋다.     
* 매니저 노드에서 위와 같은 명령어를 입력하면 토큰 변경이 이루어진다.     
* `--rotate` 명령어 뒤에 변경할 토큰의 대상을 입력하면 된다.     
     

```shell
docker swarm leave
docker node rm swarm-node -1  
```
* 만약, 스웜 모드를 해제하고 싶다면 아래 명령어를 입력한다.    
* 단, 매니저 노드는 워커 노드를 DOWN 으로 인지할 뿐 워커 노드를 삭제하지 않으므로 docker node rm 명령어를 입력해주어야한다.    

```
docker swarm leave --force
```
* 참고로 매니저 노드는 --force 옵션을 붙여야 삭제가 가능하다.  
* 매니저 노드를 스웜 클러스터에서 삭제하면, 클러스터 정보도 삭제되므로 주의하자.   

```
docker node promote swarm-worker1
docker node demote swarm-worker1
```
* 워커 노드를 매니저 노드로 변경하려면 docker node promote 명령어를 사용한다.   
* 매니저 노드를 워커 노드로 변경하려면 docker node demote 명령어를 사용한다.   
* 단, 매니저 노드가 한개일때, demote 는 불가능하다.    

## 스웜 모드 서비스 
### 스웜 모드 서비스 개념

지금까지 사용해온 도커 명령어의 제어 단위는 컨테이너다.    
스웜 모드에서 제어하는 단위는 컨테이너가 아닌 **서비스이다.**   
 
**서비스란?**       
* 같은 이미지에서 생성된 컨테이너의 집합     
* 서비스를 제어하면 해당 서비스 내의 컨테이너에 같은 명령이 수행된다.     
* 서비스 내에 컨테이너는 1개 이상 존재할 수 있으며 컨테이너들은 각 워커 노드와 매니저 노드에 할당된다. 
* 이러한 컨테이너들을 **컨테이너 태스크**라고 한다.  
  
**예시**
1. 이미지로 서비스를 생성하고, 컨테이너의 수를 3개로 설정한다.   
2. 스웜 스케줄러는 서비스의 정의에 따라 컨테이너를 할당할 적합한 노드를 선정하고,   
   해당 노드에 컨테이너를 분산해서 저장한다. 
3. 각 노드에 컨테이너가 할당된다.(각 노드에 하나씩 할당되지 않을 수 있다.)   
  
이처럼 함께 생성된 컨테이너를 **레플리카**라고 하며,     
서비스에 설정된 레플리카의 수만큼의 컨테이너가 스웜 클러스터내에 존재해야한다.  
    
스웜은 서비스의 컨테이너들에 대한 상태를 계속 확인하고 있다가      
서비스내에 정의된 레플리카의 수만큼 컨테이너가 스웜 클러스터에 존재하지 않으면 새로운 컨테이너 레플리카를 생성한다.   

즉, 컨테이너가 할당된 `노드`가 다운되면 매니저는 사용 가능한 다른 노드에 같은 컨테이너를 생성한다.     
서버가 다운되지 않더라도 서비스내의 컨테이너 중 일부가 작동을 멈춰 정지한 상태도 마찬가지다.     
  
서비스는 롤링 업데이트 기능도 지원한다.    
서비스 내 컨테이너들의 이미지를 일괄적으로 업데이트해야할 때,      
컨테이너들의 이미지를 순서대로 변경해 서비스 자체가 다운되는 시간 없이 컨테이너 업데이트를 진행할 수 있다.    

```
롤링 업데이트는    
여러 개의 서버, 컨테이너등으로 구성된 클러스터의 설정이나 데이터 등을 변경하기 위해 하나씩 재시작하는 것을 의미한다.    
롤링 업데이트를 사용하지 않고 모든 서버나 컨테이너를 한 번에 재시작하면 제공하는 서비스에 다운 시간이 생기지만     
롤링 업데이트를 이용하면 하나를 업데이트해도, 다른 서버나 컨테이너는 작동중이기 때문에 지속적인 서비스가 가능하다.   
```  

### 서비스 생성 
#### 첫번째 서비스 생성해보기  

서비스를 사용하기 위한 명령어는 docker service 로 시작한다.   

```
docker service create \
이미지:태그 \
명령어 
```
* 서비스를 생성하려면 docker service create 명령어를 사용한다.   
* 서비스 내의 컨테이너는 detached 모드로, -d 옵션을 사용해 동작할 수 있는 이미지를 사용해야한다.  
* `docker service create 이미지(프로세스가 없는):태그` 와 같이 사용하면,   
  컨테이너 내부를 차지하고 있는 프로세스가 없어 컨테이너가 정지될 것이고,   
  스웜 매니저는 서비스의 컨테이너에 장애가 생긴것으로 판단해 컨테이너를 계속 반복해서 생성할 것이다.   
* 위 예제는 우분투 컨테이너 내에서 `hello world`를 출력하기에 사용이 가능하다.  

```
docker service ls
docker service ps [서비스 이름]
```
* 스웜 클러스터내의 서비스 목록을 확인할 수 있다.   
* 서비스의 자세한 사항은 docker service ps 를 통해 확인이 가능하다.   

```
docker service rm [서비스 이름]
```
* 서비스를 삭제하고자 한다면 `docker service rm [서비스 이름]`를 입력하면 된다.  
* docker rm 과 달리 서비스의 상태가 어떻더라도 삭제 가능하다.   

```
docker service create --with-registry-auth \
...
```
서비스 생성을 위해 private 저장소 또는 레지스트리에서 이미지를 받아올 경우,     
매니저 노드에서 로그인한 뒤 docker create 명령어에 --with-registry-auth 를 추가해 사용하면       
워커 노드에서 별도 로그인을 하지 않아도 이미지를 받아올 수 있다.     

#### 예시   

```
docker service create --name myweb \
--replicas 2 \
-p 80:80 \
nginx
```
* --replica 옵션을 통해 2개의 컨테이너를 생성한다.(노드에 적절히 배분)      
* 생성된 서비스의 컨테이너는 docker service ps `[서비스 이름]` 으로 확인할 수 있다.    

```
docker service scale meyweb=4
```
* `docker service scale 이미지이름=개수` 를 통해 레플리카 개수룰 조정 가능하다.   
* 매니저1, 워커2인 상태에서 위 명령어를 실행했을 때, 하나의 워커 노드에 2개의 컨테이너가 띄워져있다.   
* 80번 포트가 중첩되기에 문제가 생길것이라 예상 되지만, 전혀 문제가 되지 않다.   
* 각 컨테이너들이 호스트의 80번 포트에 연결된 것이 아니라,   
  실제로 각 노드의 80 번 포트로 들어온 요청을 위 4개의 컨테이너 중 1개로 리다이렉트 하기 때문이다.     
  
참고로, 그웜 모드는 라운드 로빈 방식으로 서비스내의 접근할 컨테이너를 결정한다.    
각 노드의 트래픽이나 자원 사용량등을 고려해 로드 밸런싱을 해야한다면 이 방식은 적합하지 않다.   

#### global 서비스 생성하기  

소비스 모드는 2가지다.         
* 복제 모드   
* 글로벌 모드  

글로벌 서비스는 스웜 클러스터 내에서 사용할 수 있는 노드에 컨테이너를 반드시 하나씩 생성한다.     
따라서 글로벌 모드로 생성한 서비스는 레플리카셋의 수를 별도로 설정하지 않는다.     
글로벌 서비스는 스웜 클러스터를 모니터링하기 위한 에이전트 컨테이너등을 생성할 때 유용하다.     

```
docker service create --name global_web \
--mode global \
nginx 
```
* `docker service create` 명령어에 `--mode global` 옵션을 사용하면 된다.   


### 스웜 모드의 서비스 장애 복구 

복제모드로 설정된 서비스의 컨테이너가 정지하거나 특정 노드가 다운되면      
스웜 매니저는 새로운 컨테이너를 생성해 자동으로 이를 복구한다.    
 
만약, 워커 노드의 도커 데몬이 죽었다면?     
* 다른 노드에서 컨테이너가 생성된다.    
* 그러나, 장애를 복구해도 그 노드에 컨테이너가 다시 할당되지는 않는다.   
* 즉, rebalancing 은 일어나지 ㅇ낳는다.     
* 이를 위해서는 scale 명령어를 통해 컨테이너 수를 줄이고 다시 늘려야한다.  

**궁금증 매니저가 죽으면?**   
* 죽는다  
* 이를 위해 매니저를 3개 이상 두는 것이 좋다.    
 
### 서비스 롤링 업데이트 
  
스웜 모드는 롤링 업데이트를 자체적으로 지원하며, 매우 간단하게 사용할 수 있다.    

```
docker service create --name myweb2 \
--replicas 3 \
nginx:1.10
```
```
docker service update \
--image nginx:1.11 \ 
myweb2
```
각 컨테이너의 이미지가 변경되며 빠른 속도로 롤링 업데이트가 진행된다.      
    
`docker service ps 서비스이름`을 통해 확인했을 때    
`\_`이 붙어있는 컨테이너는 업데이트의 대상이 되어 삭제된 컨테이너며       
`\_` 가 붙어있지 않은 컨테이너가 롤링 업데이트로 새롭게 생성된 컨테이너다.        

* `\_`가 붙어있는 컨테이너는 어떠한 이유로든 동작을 멈춘 컨테이너로서, 서비스에서 컨테이너 변경 기록을 나타낸다.   


```
docker service create \
--replicas 4 \
--name myweb3 \
--update-delay 10s \
--update-parallelism \
nginx:1.10
```
* 롤링 업데이트 주기  
* 업데이트시, 동시에 진행할 컨테이너 개수   
* 업데이트 실패시    
  
등을 설정할수 있다.   


```
docker service insect --pretty myweb3
~~
On failure: pause
```
* 롤링 업데이트 설정은 `docker service insect --pretty`를 통해 상세히 확인 가능하다.   
* `On failure: pause` 는 업데이트 도중 오류가 발생하면 롤링 업데이트를 중지하는 구문이다. 
* 실패에 대해 `--update-failure-action` 인자값을 continue 로 지정하면 오류 발생해도 롤링을 진행한다. 

```
docker service rollback myweb3
```
* 롤백도 가능하다. 


### 서비스 컨테이너에 설정 정보 전달하기 
 
컨테이너 애플리케이션 실행을 위한 설정들을      
외부에서 설정할 수 있도록 -v 와 -e 를 통해 설정할 수 있도록 했다.          
  
그러나 스웜 모드와 같은 서버 클러스터에서 파일 공유를 위해 설정 파일을 호스트마다 마련하는 것은 매우 비효율적이다.  
또한 민감한 정보를 환경변수로 설정하는 것도 보안상 좋지 않다.  

이를 위해 스웜 모드는 secret 과 config 라는 기능을 제공한다.     

* secret : 보안에 민감한 데이터 전송을 위해서 사용한다.  
* config : nginx 나 레지스트리 설정 파일과 같이 암호화할 필요가 없는 설정값들에 대해 쓰일 수 있다.  
   
그러나, secret과 config는 스웜 모드에서만 사용될 수 있는 기능이다.    

#### secret 사용하기 

```
echo 1q2w3e4r | docker secret create my_mysql_password -
```
* secret 애 값을 저장했다.  
* `docker secret inspect my_mysql_password`를 통해 조회해도 실제값 확인이 안된다.  
* secret 값은 매니저 노드간에 암호화된 상태로 저장되는데   
  메모리에 저장되기에 서비스 컨테이너가 삭제될 경우 함께 삭제되는 휘발성을 띈다.  
  
```
docker service create \
  --name mysql \
   --replicas 1 \
   --secret source=my_mysql_password, target=mysql_root_password \
   --secret source=my_mysql_password, target=mysql_password \
   -e MYSQL_ROOT_PASSWORD_FILE=""
   -e MYSQL_PASSWORD_FILE=""
   -e MYSQL_DATABASE=""
   ...
```
* --secret 옵션을 통해 컨테이너로 공유된 값은        
   기본적으로 컨테이너 내부의 `/run/secrets/` 디렉터리에 마운트 된다.      
* target 에 절대값을 이용해서 다른 경로에 secret 파일을 공유할 수도 있다.    
* 위 예시는 `/run/secrets/` 에 `mysql_root_password`파일이 있고 1q2w3e4r 이 있다.  

그러나 위 방식은 -e MYSQL_PASSWORD_FILE 로 특정 경로의 파일로부터 비밀번호를 로드할 수 있도록 해야한다.  

####  config 사용하기 

config를 사용하는 방법은 secret과 거의 동일하다.    

```
docker config create registry-config config.yml  
``` 
* 레지스트리 설정 파일을 registry-config 파일이라는 이름의 config로 저장한다.  

```
docker config ls
docker config inspect registry-config

~~
Data: ""
```
* Data 항목은, config 에 입력된 값을 base64로 인코딩한 뒤 저장한 값이다.       
* 디코딩하면, config 의 내용은 사설 레지스트리의 설정 내용을 변경했을 때 사용했던 파일이다.   

```
docker service create --name yml_registry -p 5000:5000 \
--config source=registry-config, target=/etc/docker/registry/config.yml \
registry:2.6
```
* 사용법은 secret과 동일하다.  

secret과 config의 값을 수정할 수는 없지만,   
서비스 컨테이너가 새로운 값을 사용해야한다면, docker service update 명령어의       
`--config-rm`, `--config-add`, `--secret-rm`, `--secret-add` 옵션을 사용해 서비스가 사용하는   
secret이나 config를 추가하고 삭제할 수 있다.     
이를 잘 활용하면 이미지를 다시 빌드할 필요 없이도 여러 설정값의 애플리케이션을 쉽게 사용할 수 있다.   

### 도커 스웜 네트워크 

스웜 모드는 여러 개의 도커 엔진에 같은 네트워크를 분산해서 할당하기 때문에      
각 도커 데몬의 네트워크가 하나로 묶인, 이른바 네트워크 풀이 필요하다.      
이뿐만 아니라, 서비스를 외부로 노출했을 때    
어느 노드로 접근하더라도 해당 서비스의 컨테이너에 접근할 수 있게 라우팅 기능이 필요하다.    

이러한 네트워크의 기능은 스웜 모드가 자체적으로 지원하는 네트워크 드라이버를 통해 사용할 수 있다.   

#### ingress 네트워크 

* 스웜 클러스터를 생성하면 자동으로 등록하는 네트워크  
* 어떤 스웜 노드에 접근하더라도 서비스내의 컨테이너에 접근할 수 있게 설정하는 라우팅 메시를 구성하고,   
  서비스내의 컨테이너에 대해 접근을 라운드 로빈 방식으로 분산하는 로드 밸런싱을 담당한다.   
* ingress 는 포트를 노출하지 않아도 된다는점과 이에 따라 각 서비스의 포트를 관리하지 않아도 있다는 장점이 있다.   

#### 오버레이 네트워크 

* ingress 네트워크는 오버레이 네트워크 드라이버를 사용한다.   
* 오버레이 네트워크는 여러개의 도커 데몬을 하나으 ㅣ네트워크 풀로 만드는 네트워크 가상화 기술이다.    
* 도커에 오버레이 네트워크를 적용하면, 여러 도커 데몬에 존재하는 컨테이너가 서로 통신할 수 있다.    
* 즉, 여러개의 스웜 노드에 할당된 컨테이너는   
  오버레이 네트워크의 서브넷에 해당하는 IP 대역을 할당받고 이 IP를 통해 서로 통신하는 것이다.  
* 매니저는 별도의 포트포워딩 없이 핑 전송이 가능하다.  

#### docker_gwbridge 네트워크 
 
오버레이 네트워크를 사용하지 않는 컨테이너는 기본적으로 존재하는 브리지 네트워크를 사용해 외부와 연결한다.      
그러나, ingress 를 포함한 모든 오버레이 네트워크는 이와 다른 브리지 네트워크인 docker_gwbridge 네트워크와 함께 사용된다.     
docker_gwbridge 네트워크는 외부로 나가는 통신 및 오버레이 네트워크의 트래픽 종단점 역할을 담당한다.        
   
docker_gwbridge 네트워크는 컨테이너 내부의 네트워크 인터페이스 카드 중 eth1 과 연결된다.  

#### 사용자 정의 오버레이 네트워크 

스웜모드는 자체 키-값 저장소를 갖고 있으므로 별도의 구성 없이 사용자 정의 오버레이 네트워크를 생성 및 사용가능하다.   

```
docker network create \
--subnet 10.0.9.0/24 \
-d overlay \
myoverlay
```
* 오버레이 네트워크는 생성한 즉시 모든 노드에 적용되는 것이 아니라    
  각 노드에 해당 오버레이 네트워크를 사용하는 서비스의 컨테이너가 할당될 때 적용된다.    
* 매니저 노드에서 docker service create 명령어를 통해서만 이 네트워크를 사용하는 서비스를 생성할 수 있다.  
* docker run --net 명령어로 스웜 모드의 오버레이 네트워크를 사용하려면   
  네트워크를 생성할 때 `attachable`을 추가해야한다.  

```
docker service --name overlay_service \
--network myoverlay \
--replicas 2 \
alicek106/book:hostname
```
* -p 옵션을 사용하지 않음으로써 서비스를 외부로 노출하지 않으며 컨테이너는 ingress 네트워크를 사용하지 않는다.   

### 서비스 디스커버리 
  
같은 컨테이너를 여러 개 만들어 사용할 때 쟁점이 되는 부분 중 하나는        
새로 생성된 컨테이너 생성의 발견 혹은 없어진 컨테이너의 감지다.       
일반적으로 이동작은 주키퍼, etcd 등의 분산 코디네이터를 외부에 두고 사용해서 해결하지만      
스웜 모드는 서비스 발견 기능을 자체적으로 지원한다.     
스웜 모드의 서비스 디스커버리는 오버레이 네트워크를 사용하는 서비스에 대해 작동한다.  


* 서버2 
* 클라1
 
서버를 3으로 늘리고, 클라에서 서버로 접근을 시도해도 서버 3에 접근이 가능하다.          
오버레이 네트워크에 속하도록 서비스를 생성했다면 도커 스웜의 DNS가 이를 자동으로 변환한다.(라운드 로빈 방식)   
  
사실 server 라는 호스트 이름이 3개의 IP를 가지는 것이 아니라, 서비스의 VIP를 가지는 것이다.   
즉, `DNS` -> `VIP` -> `실제 컨테이너의 IP` 로 포워딩 하는 것이다.     

```
docker service create --name server \
--replicas 2 --network discovery \
--endpoint-mode dnsrr \
alicek106/book:hostname
```
* `--endpoint-mode dnsrr` 를 통해 VIP 방식이 아닌 DNS 방식을 사용할 수 있다.(라운드로빈)      
* 그런데 이 경우 애플리케이션에 따라 캐시 문제로 인해 서비스 발견이 정상적이지 않을때가 있어서 가급적 VPI 추천 

### 스웜 모드 볼륨 

스웜모드에서는 `도커 볼륨 `/`호스트외 디렉토리 공유` 를 사용할지 더 명확히 구분해 사용가능하다.    
즉, 서비스를 생성할 때 도커 볼륨을 사용할지 호스트와 디렉터리를 공유할지 명시한다.  

##### volume 타입의 볼륨 생성 

```
docker service create --name ubuntu \
--mount type=volume, source=myvol, target=/root \
ubuntu:14.04 \
ping docker.com
```
* type : 마운트 타입 지정(예시는 볼륨)  
* source : 사용할 볼륨 지정 
* target : 컨테이너 내부에 마운트될 디렉터리 위치 


서비스의 컨테이너에서 볼륨에 공유할 컨테이너의 디렉터리에 파일이 이미 존재하면       
이 파일들은 볼륨에 복사되고, 호스트에서 별도의 공간을 차지하게 된다.      
그러나 서비스를 생성할 때 볼륨 옵션에 volume-nocopy를 추가하면 컨테이너의 파일들이 볼륨에 복사되지 않도록 할 수 있다.  

```
docker service create --name ubuntu \
--mount type=volume, source=myvol, target=/root, volume-nocopy \
ubuntu:14.04 \
ping docker.com
```

#### bind 타입 볼륨 생성 

바인드 타입은 호스트와 디렉터리를 공유할 때 사용한다.   

```
docker service create --name ubuntu \
--mount type=bind, source=/root/host, target=/root/container \
ubuntu:14.04 \
ping docker.com
```
* 바인드 타입은, 공유할 호스트 디렉토리가 필요하므로 source 옵션을 반드시 명시해야한다.

#### 스웜 모드에서 볼륨의 한계점 
    
스웜클러스터에서 볼륨을 사용하기란 상당히 까다롭다.        
모든 노드가 볼륨 데이터를 가지고 있어야하기 때문이다.      
스웜 매니저에 내장된 스케줄러가 컨테이너를 할당할 때 어느 노드에 할당해도 서비스에 정의된 볼륨을 사용할 수 있어야한다.   
그렇기에 스웜 모드에서는 도커 볼륨, 또는 호스트와의 볼륨 사용이 적합하지 않을 수 있다.     
 
이를 해결하기 위한 일반적인 방법은 퍼시스턴스 스토리지를 사용하는 것이다.      
퍼시스턴스 스토리지는 호스트와 컨테이너와 별개로 외부에 존재해 네트워크로 마운트할 수 있는 스토리지다.  
그러나 이러한 퍼시스턴스 스토리지는 도커가 자체 제공하지 않으므로 서드파티를 사용하거나 nfs/dfs 를 구성해야한다.   
 
또는 각 노드에 라벨을 붙여 서비스에 제한을 설정하는 방법도 있다.     
노드에 라벨을 설정해 특정 서비스의 동작에 필요한 볼륨이 존재하는 노드에만 컨테이너를 할당할 수 있게 설정하는 것이다.  
근본적인 해결책이 될 수는 없지만, 소규모 클러스터와 테스트 환경에서는 유용하게 활용될 수 있다.  

## 도커 스웜 모드 노드 다루기 

서비스를 좀더 유연하게 할당하려면 새로운 노드 추가뿐만 아니라 노드를 다루기 위한 전랴도 필요하다.    

### 노드 AVAILABILITY 변경하기 

매니저 노드는 최대한 부하를 받지 않도록 서비스를 할당받지 않게 하는 것이 좋다.  
AVAILABILITY 상태를 설정함으로써 컨테이너의 할당 가능 여부를 변경 가능하다.  

#### ACTIVE
```
docker node update \
--availability active \
swarm-worker1
```
노드가 서비스의 컨테이너를 할당받을 수 있는 상태  


#### Drain

```
docker node update \
--availablity drain \
swarm-worker1
``` 
스웜 매니저의 스케줄러는 컨테이너를 해당 노드에 할당하지 않는다.           
일반적으로 매니저 노드에서 설정하는 상태지만, 노드에 문제가 생겨 일시적으로 사용하지 않을때도 유용하다.     
참고로, 실행중인 서비스의 컨테이너는 중지되고 Active 상태의 노드로 다시 할당된다.      
이전에 말했듯이 리밸런싱을 하려면 scale 을 재조정해야한다.    

#### Pause 

Pause 상태는 서비스의 컨테이너를 더는 할당 받지 않지만,   
실행중인 컨테이너가 중지되지 않는다는 점이 다르다.   

```
docker node update \
--availablity pause \
swarm-worker1
``` 

### 노드 라벨 추가 
라벨을 추가하는 것은 노드를 분류하는 것과 비슷하다.(키/값)  
특정 노드에 라벨을 추가하면 서비스를 할당할 때, 컨테이너를 생성할 노드의 그룹을 선택하는 것이 가능해진다.   
특정 노드가 ssd, 특정 노드가 hdd 사용한다면 각 노드에 맞추어 컨테이너 배포 가능    

#### 노드 라벨 추가 

```
docker node update \
--label-add storage=ssd \
swarm-worker1
```
* `--label-add`를 통해 라벨을 설정할 수 있다.  

#### 서비스 제약 설정 
  
`docker service create` 명령어에 `--constraint` 옵션을 추가해 서비스의 컨테이너가 할당될 노드의 종류를 선택할 수 있다.    
노드의 ID, 호스트 이름, 도커 데몬의 라벨등으로도 제약조건을 설정할 수 있다.    

**node.labels 제약조건**   
```
docker service create --name label_test \
--constraint 'node.labels.storage == ssd ' \
--replicas=5 \
ubuntu:14.04 \
ping docker.com
```
* storage 라벨이 ssd로 설정된 노드에만 컨테이너를 생성하도록 설정했다.  
* 제한 조건에 해당하는 노드를 찾지 못할 경우 서비스의 컨테이너는 생성되지 않는다.  

**node.id 제약조건**     
```
docker node ls | grep swarm-workter2

> ID 이름 상태 
```
````
docker service create --name label_test \
--constraint 'node.id == ID ' \
--replicas=5 \
ubuntu:14.04 \
ping docker.com
````
* 노드의 ID 를 통해 컨테이너를 생성할 수 있다.  


**node.hostname과 node.role 제약조건**   
```
docker service create --name label_test \
--constraint 'node.hostname == swarm-worker1 ' \
--replicas=5 \
ubuntu:14.04 \
ping docker.com
```
* 특정 노드 호스트 이름에만 생성 

```
docker service create --name label_test \
--constraint 'node.role == manager ' \
--replicas=5 \
ubuntu:14.04 \
ping docker.com
```
* 매니저만 생성 

#### engine.labels 제약조건 

도커 엔진,   
즉 도커 데몬 자체에 라벨을 설정해 제한 조건을 설정할 수 있지만 이를 사용하려면 도커 데몬의 실행 옵션을 변경해야한다.    

```
DOCKER_OPTS=".. --label=mylabel=workter2 --label mylabel2=second_worker ..."
```

```
docker service create --name engine_label \
--constraint 'engine.labels.mylabel == worker2' \
--replicas=3 \
ubuntu:14,04 \
ping docker.com
```
* 도커 데몬의 라벨중 mylabel 이라는 키가 workter2라는 값으로 설정된 노드에 서비스의 컨테이너를 할당한다.   

```
docker service create --name engine_label \
--constraint 'engine.labels.mylabel == worker2' \
--constraint 'engine.labels.mylabel2 == second_worker' \
--replicas=3 \
ubuntu:14,04 \
ping docker.com
```
* 동시에 여러개도 가능하다. 









  
 


